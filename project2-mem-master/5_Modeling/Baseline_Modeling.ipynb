{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Modeling Results\n",
    "- Find the best sampling technique to balance the data \n",
    "    - SMOTE Up-Sampling (see table of contents below)\n",
    "- Run 7 models with 10 iterations to get baseline results \n",
    "\n",
    "![Baseline Results](Baseline_models_results.jpeg)\n",
    "\n",
    "\n",
    "\n",
    "# Table of contents <a name=\"t\"></a>\n",
    "1. [Basic Date Prep](#i)\n",
    "2. [Logistic Regression: Unbalanced performance](#para1)\n",
    "3. [Logistic Regression: Up-Sample Manual](#para2)\n",
    "4. [Logistic Regression: Up-Sample SMOOT](#para3)\n",
    "- Best balancing method: SMOTE (up-sampling)\n",
    "\n",
    "**Models**\n",
    "1. [MLP](#paragraph4)\n",
    "2. [XGBoost](#paragraph5)\n",
    "3. [Random Forest](#paragraph6)\n",
    "4. [SVC](#paragraph7)\n",
    "5. [Logistic Regression](#para3)\n",
    "6. [Naive Bayes](#paragraph9)\n",
    "7. [Decision Tree](#paragraph10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.metrics import classification_report,roc_auc_score,accuracy_score,confusion_matrix\n",
    "from sklearn.metrics import roc_curve,f1_score,precision_recall_fscore_support\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Data Prep <a name=\"i\"></a>\n",
    "- Try different modeling techniques and balance the data on not preproccessed data\n",
    "- We need to minimaly encode the data for this step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Administrative</th>\n",
       "      <th>Administrative_Duration</th>\n",
       "      <th>Informational</th>\n",
       "      <th>Informational_Duration</th>\n",
       "      <th>ProductRelated</th>\n",
       "      <th>ProductRelated_Duration</th>\n",
       "      <th>BounceRates</th>\n",
       "      <th>ExitRates</th>\n",
       "      <th>PageValues</th>\n",
       "      <th>SpecialDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>OperatingSystems</th>\n",
       "      <th>Browser</th>\n",
       "      <th>Region</th>\n",
       "      <th>TrafficType</th>\n",
       "      <th>VisitorType</th>\n",
       "      <th>Weekend</th>\n",
       "      <th>Revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Administrative  Administrative_Duration  Informational  \\\n",
       "0               0                      0.0              0   \n",
       "1               0                      0.0              0   \n",
       "2               0                      0.0              0   \n",
       "\n",
       "   Informational_Duration  ProductRelated  ProductRelated_Duration  \\\n",
       "0                     0.0               1                      0.0   \n",
       "1                     0.0               2                     64.0   \n",
       "2                     0.0               1                      0.0   \n",
       "\n",
       "   BounceRates  ExitRates  PageValues  SpecialDay Month  OperatingSystems  \\\n",
       "0          0.2        0.2         0.0         0.0   Feb                 1   \n",
       "1          0.0        0.1         0.0         0.0   Feb                 2   \n",
       "2          0.2        0.2         0.0         0.0   Feb                 4   \n",
       "\n",
       "   Browser  Region  TrafficType        VisitorType  Weekend  Revenue  \n",
       "0        1       1            1  Returning_Visitor    False    False  \n",
       "1        2       1            2  Returning_Visitor    False    False  \n",
       "2        1       9            3  Returning_Visitor    False    False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loaded in the data\n",
    "data = pd.read_csv('online_shoppers_intention.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode object/bool variables\n",
    "- we decide to one-hot encode months into quarters \n",
    "- also one-hot visitor type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 10 months, missing Jan, Apr \n",
    "# encode into quarters \n",
    "def division_func_month(div) :\n",
    "    if div == 'Feb':\n",
    "        return 1\n",
    "    elif div == 'Mar':\n",
    "        return 1\n",
    "    elif div == 'May':\n",
    "        return 2\n",
    "    elif div == 'June':\n",
    "        return 2\n",
    "    elif div == 'Jul':\n",
    "        return 3\n",
    "    elif div == 'Aug':\n",
    "        return 3\n",
    "    elif div == 'Sep':\n",
    "        return 3\n",
    "    elif div == 'Oct':\n",
    "        return 4\n",
    "    elif div == 'Nov':\n",
    "        return 4\n",
    "    elif div == 'Dec':\n",
    "        return 4\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enncode some other way too "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from object to integers\n",
    "data['quarter'] = data['Month']\n",
    "# apply function\n",
    "data['quarter'] = data['quarter'].apply(division_func_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    5274\n",
       "2    3652\n",
       "1    2091\n",
       "3    1313\n",
       "Name: quarter, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['quarter'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding for revenue and weekend\n",
    "def div_fun_visType(div) :\n",
    "    if div == 'Returning_Visitor':\n",
    "        return 1\n",
    "    if div == 'New_Visitor':\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from boolean to integers\n",
    "data['VisitorType_encode'] = data['VisitorType']\n",
    "# apply function\n",
    "data['VisitorType_encode'] = data['VisitorType_encode'].apply(div_fun_visType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10551\n",
       "2     1694\n",
       "0       85\n",
       "Name: VisitorType_encode, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['VisitorType_encode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.307426597582037 % Made the purchase\n",
      "81.69257340241796 % Did not make the purchase\n"
     ]
    }
   ],
   "source": [
    "print(1908/10422*100,'% Made the purchase')\n",
    "print(100-18.307426597582037,'% Did not make the purchase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.copy()\n",
    "data1 = data1.drop(['VisitorType','Month'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revenue (Y) and weeked only have 2 unique values so there is no need to encode\n",
    "data1 = pd.get_dummies(data1, columns=['VisitorType_encode','quarter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression: Unbalanced performance <a name=\"para1\"></a>\n",
    "- use MinMaxScaler to standerdize data \n",
    "- run logistic regression without sampling (balancing data)\n",
    "\n",
    "Back to [Table of Contents](#t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input features (X) and target variable (y)\n",
    "y = data1.Revenue\n",
    "X = data1.drop('Revenue', axis=1)\n",
    "\n",
    "# make a function as we will be reusing it \n",
    "def logistic_regression_function(y, X):\n",
    "    \n",
    "    # lists for f1-score and AUC\n",
    "    f1_score_lst = []\n",
    "    auc_lst = []\n",
    "    \n",
    "    scaler = MinMaxScaler() # innitialize function\n",
    "    x_scaled = scaler.fit_transform(X) # standerdize data (X - no target feature)\n",
    "    \n",
    "    # loop to calculate f1 and auc scores and present averages after 10 runs\n",
    "    for count in range (1,10):\n",
    "    \n",
    "        # innitialize logistic regression \n",
    "        clf_0 = LogisticRegression(solver='lbfgs', max_iter=4000) # increase max_iter to converge data (default = 100)\n",
    "\n",
    "        # create training and testing vars\n",
    "        Xs_train, Xs_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=123, shuffle=True)\n",
    "        #print ('X_train: ',X_train.shape,'y_train', y_train.shape)\n",
    "        #print ('X_test: ',X_test.shape,'y_test: ', y_test.shape)\n",
    "\n",
    "        # Train model\n",
    "        clf_0.fit(Xs_train, y_train)\n",
    "\n",
    "        # Predict on training set\n",
    "        pred_y_0 = clf_0.predict(Xs_test)\n",
    "\n",
    "        #10-fold cross validation\n",
    "        kfold = model_selection.KFold(n_splits=10, random_state=123, shuffle=True)\n",
    "        scoring = 'accuracy'\n",
    "        results = model_selection.cross_val_score(clf_0, Xs_train, y_train, cv=kfold, scoring=scoring)\n",
    "\n",
    "        #calculate f1-score and AUC\n",
    "        clf_0_roc_auc = roc_auc_score(y_test, pred_y_0)\n",
    "        #f1_score = precision_recall_fscore_support(y_test, pred_y_0, average='weighted')[2]\n",
    "        \n",
    "        #calculate average f1-score and AUC\n",
    "        f1_score_lst.append(precision_recall_fscore_support(y_test, pred_y_0, average='weighted')[2])\n",
    "        auc_lst.append(clf_0_roc_auc)\n",
    "\n",
    "    # display average AUC and F1 score\n",
    "    print('F1 {:.4f}; AUC {:.4f} '.format(np.mean(f1_score_lst),np.mean(auc_lst)))\n",
    "    \n",
    "    # Is our model still predicting just one class?\n",
    "    print('Model is predicting ',np.unique( pred_y_0 ),'class' )\n",
    "\n",
    "    # Print accuracy score\n",
    "    print('Accuracy of classifier on test set: {:.3f}'.format(clf_0.score(Xs_test, y_test)))\n",
    "    \n",
    "    # Display 10-fold cross validation average accuracy\n",
    "    print(\"10-fold cross validation average accuracy of clf_0: %.3f\" % (results.mean()))\n",
    "    \n",
    "    # calculate cunfusion matrix\n",
    "    confusion_matrix_y = confusion_matrix(y_test, pred_y_0)\n",
    "    print('Confusion Matrix for Classfier:')\n",
    "    print(confusion_matrix_y)\n",
    "\n",
    "    print('Classification Report for Classfier:')\n",
    "    print(classification_report(y_test, pred_y_0))\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.8441; AUC 0.6295 \n",
      "Model is predicting  [False  True] class\n",
      "Accuracy of classifier on test set: 0.872\n",
      "10-fold cross validation average accuracy of clf_0: 0.875\n",
      "Confusion Matrix for Classfier:\n",
      "[[2042   27]\n",
      " [ 289  108]]\n",
      "Classification Report for Classfier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.99      0.93      2069\n",
      "        True       0.80      0.27      0.41       397\n",
      "\n",
      "    accuracy                           0.87      2466\n",
      "   macro avg       0.84      0.63      0.67      2466\n",
      "weighted avg       0.86      0.87      0.84      2466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# call function\n",
    "logistic_regression_function(y,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - Up-Sample minority class  <a name=\"para2\"></a>\n",
    "\n",
    "- Up-sampling is the process of randomly duplicating observations from the minority class in order to reinforce its signal.\n",
    "- There are several heuristics for doing so, but the most common way is to simply resample with replacement.\n",
    "\n",
    "### Important: Do not up-sample before splitting you data\n",
    "- By oversampling before splitting into training and validation datasets, you “bleed” information from the validation set into the training of the model.\n",
    "- If I upsample a dataset before splitting it into a train and validation set, I could end up with the same observation in both datasets. \n",
    "- As a result, a complex enough model will be able to perfectly predict the value for those observations when predicting on the validation set, inflating the accuracy and recall.\n",
    "- By oversampling only on the training data, none of the information in the validation data is being used to create synthetic observations. So these results should be generalizable. \n",
    "- You should only balance the training set, and leave the test set unbalanced to avoid introducing error into your test data.\n",
    "\n",
    "Let's sample the right way by sampling after the data split. For this we need to slightly change our logistic regression.\n",
    "\n",
    "Back to [Table of Contents](#t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.8451; AUC 0.7915 \n",
      "Model is predicting  [False  True] class\n",
      "Accuracy of classifier on test set: 0.834\n",
      "10-fold cross validation average accuracy of clf_0: 0.800\n",
      "Confusion Matrix for Classfier:\n",
      "[[1764  305]\n",
      " [ 104  293]]\n",
      "Classification Report for Classfier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.85      0.90      2069\n",
      "        True       0.49      0.74      0.59       397\n",
      "\n",
      "    accuracy                           0.83      2466\n",
      "   macro avg       0.72      0.80      0.74      2466\n",
      "weighted avg       0.87      0.83      0.85      2466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Separate input features (X) and target variable (y)\n",
    "y = data1.Revenue\n",
    "X = data1.drop('Revenue', axis=1)\n",
    " \n",
    "# lists for f1-score and AUC\n",
    "f1_score_lst = []\n",
    "auc_lst = []\n",
    "    \n",
    "scaler = MinMaxScaler() # innitialize function\n",
    "x_scaled = scaler.fit_transform(X) # standerdize data (X - no target feature)\n",
    "x_scaled = pd.DataFrame(x_scaled) # convert back to df neccesary for concat upsampling\n",
    "x_scaled.columns = X.columns # name the columns \n",
    "    \n",
    "# loop to calculate f1 and auc scores and present averages after 10 runs\n",
    "for count in range (1,10):\n",
    "    \n",
    "    # innitialize logistic regression \n",
    "    clf_0 = LogisticRegression(solver='lbfgs', max_iter=1000) # increase max_iter to converge data (default = 100)\n",
    "\n",
    "    # create training and testing vars\n",
    "    Xs_train, Xs_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=123, shuffle=True)\n",
    "        \n",
    "    # Begin oversampling\n",
    "    oversample = pd.concat([Xs_train,y_train],axis=1)\n",
    "    max_size = oversample['Revenue'].value_counts().max()\n",
    "    lst = [oversample]\n",
    "    for class_index, group in oversample.groupby('Revenue'):\n",
    "        lst.append(group.sample(max_size-len(group), replace=True))\n",
    "    Xs_train = pd.concat(lst)\n",
    "    y_train=pd.DataFrame.copy(Xs_train['Revenue'])\n",
    "    del Xs_train['Revenue']\n",
    "\n",
    "    # Train model\n",
    "    clf_0.fit(Xs_train, y_train)\n",
    "\n",
    "    # Predict on training set\n",
    "    pred_y_0 = clf_0.predict(Xs_test)\n",
    "\n",
    "    #10-fold cross validation\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=123, shuffle=True)\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(clf_0, Xs_train, y_train, cv=kfold, scoring=scoring)\n",
    "\n",
    "    #calculate f1-score and AUC\n",
    "    clf_0_roc_auc = roc_auc_score(y_test, pred_y_0)\n",
    "    \n",
    "    #calculate average f1-score and AUC\n",
    "    f1_score_lst.append(precision_recall_fscore_support(y_test, pred_y_0, average='weighted')[2])\n",
    "    auc_lst.append(clf_0_roc_auc)\n",
    "\n",
    "# display average AUC and F1 score\n",
    "print('F1 {:.4f}; AUC {:.4f} '.format(np.mean(f1_score_lst),np.mean(auc_lst)))\n",
    "    \n",
    "# Is our model still predicting just one class?\n",
    "print('Model is predicting ',np.unique( pred_y_0 ),'class' )\n",
    "\n",
    "# Print accuracy score\n",
    "print('Accuracy of classifier on test set: {:.3f}'.format(clf_0.score(Xs_test, y_test)))\n",
    "    \n",
    "# Display 10-fold cross validation average accuracy\n",
    "print(\"10-fold cross validation average accuracy of clf_0: %.3f\" % (results.mean()))\n",
    "    \n",
    "# calculate cunfusion matrix\n",
    "confusion_matrix_y = confusion_matrix(y_test, pred_y_0)\n",
    "print('Confusion Matrix for Classfier:')\n",
    "print(confusion_matrix_y)\n",
    "\n",
    "print('Classification Report for Classfier:')\n",
    "print(classification_report(y_test, pred_y_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now the model is no longer predicting just one class disproportionetly. While the accuracy also took a nosedive, it's now more meaningful as a performance metric.\n",
    "\n",
    "- AUC, F1, accuracy and classification report is now similar around 81% (also a good results)\n",
    "- It means that there is a 81% chance that the model will correclty classify whether a user made a purchase or not \n",
    "\n",
    "Let's try Up-sampling using SMOTE which is considered to be a better alternative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up-sample with SMOTE - Logistic Regression <a name=\"para3\"></a>\n",
    "- Works by selecting examples that are close in the feature space, drawing a line between the examples in the feature space and drawing a new sample at a point along that line\n",
    "- Specifically, a random example from the minority class is first chosen. Then k of the nearest neighbors for that example are found (typically k=5). A randomly selected neighbor is chosen and a synthetic example is created at a randomly selected point between the two examples in feature space\n",
    "- This procedure can be used to create as many synthetic examples for the minority class as are required\n",
    "- Instalation: sudo pip install imbalanced-learn\n",
    "\n",
    "Code help: https://beckernick.github.io/oversampling-modeling/\n",
    "\n",
    "Back to [Table of Contents](#t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.8506; AUC 0.7887 \n",
      "Model is predicting  [False  True] class\n",
      "Accuracy of classifier on test set: 0.841\n",
      "10-fold cross validation average accuracy of clf_0: 0.827\n",
      "Confusion Matrix for Classfier:\n",
      "[[2677  413]\n",
      " [ 176  433]]\n",
      "Classification Report for Classfier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.87      0.90      3090\n",
      "        True       0.51      0.71      0.60       609\n",
      "\n",
      "    accuracy                           0.84      3699\n",
      "   macro avg       0.73      0.79      0.75      3699\n",
      "weighted avg       0.87      0.84      0.85      3699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import SMOTE \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separate input features (X) and target variable (y)\n",
    "y = data1.Revenue\n",
    "X = data1.drop('Revenue', axis=1)\n",
    " \n",
    "# lists for f1-score and AUC\n",
    "f1_score_lst = []\n",
    "auc_lst = []\n",
    "    \n",
    "scaler = MinMaxScaler() # innitialize function\n",
    "x_scaled = scaler.fit_transform(X) # standerdize data (X - no target feature)\n",
    "x_scaled = pd.DataFrame(x_scaled) \n",
    "x_scaled.columns = X.columns # name the columns \n",
    "    \n",
    "# loop to calculate f1 and auc scores and present averages after 10 runs\n",
    "for count in range (1,10):\n",
    "    \n",
    "    # innitialize logistic regression \n",
    "    clf_0 = LogisticRegression(solver='lbfgs', max_iter=3000) # increase max_iter to converge data (default = 100)\n",
    "\n",
    "    # create training and testing vars\n",
    "    Xs_train, Xs_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.3, random_state=123, shuffle=True)\n",
    "        \n",
    "    # this is the formula after you split the dataset\n",
    "    sm = SMOTE(random_state=123, sampling_strategy = 'minority')\n",
    "    x_train_res, y_train_res = sm.fit_sample(Xs_train, y_train)\n",
    "\n",
    "    # Train model\n",
    "    clf_0.fit(x_train_res, y_train_res)\n",
    "\n",
    "    # Predict on training set\n",
    "    pred_y_0 = clf_0.predict(Xs_test)\n",
    "\n",
    "    #10-fold cross validation\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=123, shuffle=True)\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(clf_0, x_train_res, y_train_res, cv=kfold, scoring=scoring)\n",
    "\n",
    "    #calculate AUC\n",
    "    clf_0_roc_auc = roc_auc_score(y_test, pred_y_0)\n",
    "    \n",
    "    #calculate average f1-score and AUC\n",
    "    f1_score_lst.append(precision_recall_fscore_support(y_test, pred_y_0, average='weighted')[2])\n",
    "    auc_lst.append(clf_0_roc_auc)\n",
    "\n",
    "# display average AUC and F1 score\n",
    "print('F1 {:.4f}; AUC {:.4f} '.format(np.mean(f1_score_lst),np.mean(auc_lst)))\n",
    "    \n",
    "# Is our model still predicting just one class?\n",
    "print('Model is predicting ',np.unique( pred_y_0 ),'class' )\n",
    "\n",
    "# Print accuracy score\n",
    "print('Accuracy of classifier on test set: {:.3f}'.format(clf_0.score(Xs_test, y_test)))\n",
    "    \n",
    "# Display 10-fold cross validation average accuracy\n",
    "print(\"10-fold cross validation average accuracy of clf_0: %.3f\" % (results.mean()))\n",
    "    \n",
    "# calculate cunfusion matrix\n",
    "confusion_matrix_y = confusion_matrix(y_test, pred_y_0)\n",
    "print('Confusion Matrix for Classfier:')\n",
    "print(confusion_matrix_y)\n",
    "\n",
    "print('Classification Report for Classfier:')\n",
    "print(classification_report(y_test, pred_y_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looking at the classification report we get **better results with SMOTE and will use it in our modeling**\n",
    "\n",
    "Undersampling was considered but had lower results. With undersampling you can loose important information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC <a name=\"paragraph7\"></a>\n",
    "\n",
    "Back to [Table of Contents](#t)\n",
    "\n",
    "- The next tactic is to use penalized learning algorithms that increase the cost of classification mistakes on the minority class (we will use SVC)\n",
    "- During training, we can use the argument **class_weight='balanced'**  to penalize mistakes on the minority class by an amount proportional to how under-represented it is.\n",
    "- We also want to include the argument **probability=True**  if we want to enable probability estimates for SVM algorithms\n",
    "- We can re-use a lot of the code from the function only the algorithm is different\n",
    "- Let's train a model using Penalized-SVM on the original imbalanced dataset:\n",
    "- **Warning:** SVC takes a long time - running a model 1 time is good enough "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.8519; AUC 0.7953 \n",
      "Model is predicting  [False  True] class\n",
      "Accuracy of classifier on test set: 0.841\n",
      "10-fold cross validation average accuracy of clf_3: 0.839\n",
      "Confusion Matrix for Classfier:\n",
      "[[1785  284]\n",
      " [ 108  289]]\n",
      "Classification Report for Classfier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.86      0.90      2069\n",
      "        True       0.50      0.73      0.60       397\n",
      "\n",
      "    accuracy                           0.84      2466\n",
      "   macro avg       0.72      0.80      0.75      2466\n",
      "weighted avg       0.87      0.84      0.85      2466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Separate input features (X) and target variable (y)\n",
    "y = data1.Revenue\n",
    "X = data1.drop('Revenue', axis=1)\n",
    "\n",
    "# standerdize     \n",
    "scaler = MinMaxScaler() # innitialize function\n",
    "x_scaled = scaler.fit_transform(X) # standerdize data (X - no target feature) \n",
    "x_scaled = pd.DataFrame(x_scaled) \n",
    "x_scaled.columns = X.columns # name the columns \n",
    "\n",
    "# create training and testing vars\n",
    "Xs_train, Xs_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=123, shuffle = True)\n",
    "    \n",
    "# begin up-sampling with SMOTE\n",
    "sm = SMOTE(random_state=123, sampling_strategy = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(Xs_train, y_train)\n",
    "\n",
    "# Train model\n",
    "clf_3 = SVC(kernel='rbf', \n",
    "            class_weight='balanced', # penalize\n",
    "            probability=True, random_state = 123)\n",
    "\n",
    "clf_3.fit(x_train_res, y_train_res)\n",
    "\n",
    "# Predict on training set\n",
    "pred_y_3 = clf_3.predict(Xs_test)\n",
    "\n",
    "#10-fold cross validation\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=123, shuffle = True)\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(clf_3, x_train_res, y_train_res, cv=kfold, scoring=scoring)\n",
    "\n",
    "#calculate average f1-score and AUC\n",
    "clf_3_roc_auc = roc_auc_score(y_test, pred_y_3)\n",
    "f1_score_lst = precision_recall_fscore_support(y_test, pred_y_3, average='weighted')[2]\n",
    "\n",
    "print('F1 {:.4f}; AUC {:.4f} '.format(f1_score_lst,clf_3_roc_auc))\n",
    "\n",
    "# Is our model still predicting just one class?\n",
    "print('Model is predicting ',np.unique( pred_y_3 ),'class' )\n",
    "\n",
    "print('Accuracy of classifier on test set: {:.3f}'.format(clf_3.score(Xs_test, y_test)))\n",
    "\n",
    "print(\"10-fold cross validation average accuracy of clf_3: %.3f\" % (results.mean()))\n",
    "\n",
    "confusion_matrix_y = confusion_matrix(y_test, pred_y_3)\n",
    "print('Confusion Matrix for Classfier:')\n",
    "print(confusion_matrix_y)\n",
    "\n",
    "print('Classification Report for Classfier:')\n",
    "print(classification_report(y_test, pred_y_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes <a name=\"paragraph9\"></a>\n",
    "Back to [Table of Contents](#t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.6522; AUC 0.7042 \n",
      "Model is predicting  [False  True] class\n",
      "Accuracy of classifier on test set: 0.601\n",
      "10-fold cross validation average accuracy of clf_0: 0.728\n",
      "Confusion Matrix for Classfier:\n",
      "[[1142  927]\n",
      " [  57  340]]\n",
      "Classification Report for Classfier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.55      0.70      2069\n",
      "        True       0.27      0.86      0.41       397\n",
      "\n",
      "    accuracy                           0.60      2466\n",
      "   macro avg       0.61      0.70      0.55      2466\n",
      "weighted avg       0.84      0.60      0.65      2466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Separate input features (X) and target variable (y)\n",
    "y = data1.Revenue\n",
    "X = data1.drop('Revenue', axis=1)\n",
    "\n",
    "# standerdize     \n",
    "scaler = MinMaxScaler() # innitialize function\n",
    "x_scaled = scaler.fit_transform(X) # standerdize data (X - no target feature) \n",
    "x_scaled = pd.DataFrame(x_scaled) \n",
    "x_scaled.columns = X.columns # name the columns \n",
    "\n",
    "# lists for f1-score and AUC\n",
    "f1_score_lst = []\n",
    "auc_lst = []\n",
    "\n",
    "#loop to calculate f1 and auc scores and present averages after 10 runs\n",
    "for count in range (1,10):\n",
    "\n",
    "    #Create a Gaussian Classifier\n",
    "    gnb = GaussianNB()\n",
    "\n",
    "    # create training and testing vars\n",
    "    Xs_train, Xs_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=123, shuffle=True)\n",
    "        \n",
    "    # this is the formula after you split the dataset\n",
    "    sm = SMOTE(random_state=123, sampling_strategy = 'minority')\n",
    "    x_train_res, y_train_res = sm.fit_sample(Xs_train, y_train)\n",
    "    \n",
    "    #Train the model using the training sets\n",
    "    gnb.fit(x_train_res, y_train_res)\n",
    "    \n",
    "    #Predict the response for test dataset\n",
    "    pred_y_4 = gnb.predict(Xs_test)\n",
    "\n",
    "    #10-fold cross validation\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=123, shuffle=True)\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(gnb, x_train_res, y_train_res, cv=kfold, scoring=scoring)\n",
    "\n",
    "    #calculate AUC\n",
    "    clf_4_roc_auc = roc_auc_score(y_test, pred_y_4)\n",
    "    \n",
    "    #calculate average f1-score and AUC\n",
    "    f1_score_lst.append(precision_recall_fscore_support(y_test, pred_y_4, average='weighted')[2])\n",
    "    auc_lst.append(clf_4_roc_auc)\n",
    "\n",
    "# display average AUC and F1 score\n",
    "print('F1 {:.4f}; AUC {:.4f} '.format(np.mean(f1_score_lst),np.mean(auc_lst)))\n",
    "    \n",
    "# Is our model still predicting just one class?\n",
    "print('Model is predicting ',np.unique( pred_y_4 ),'class' )\n",
    "\n",
    "# Print accuracy score\n",
    "print('Accuracy of classifier on test set: {:.3f}'.format(gnb.score(Xs_test, y_test)))\n",
    "    \n",
    "# Display 10-fold cross validation average accuracy\n",
    "print(\"10-fold cross validation average accuracy of clf_0: %.3f\" % (results.mean()))\n",
    "    \n",
    "# calculate cunfusion matrix\n",
    "confusion_matrix_y = confusion_matrix(y_test, pred_y_4)\n",
    "print('Confusion Matrix for Classfier:')\n",
    "print(confusion_matrix_y)\n",
    "\n",
    "print('Classification Report for Classfier:')\n",
    "print(classification_report(y_test, pred_y_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network (MLP) <a name=\"paragraph4\"></a>\n",
    "Back to [Table of Contents](#t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.8667; AUC 0.8098 \n",
      "Model is predicting  [False  True] class\n",
      "Accuracy of classifier on test set: 0.858\n",
      "10-fold cross validation average accuracy of clf_3: 0.904\n",
      "Confusion Matrix for Classfier:\n",
      "[[1824  245]\n",
      " [ 104  293]]\n",
      "Classification Report for Classfier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.88      0.91      2069\n",
      "        True       0.54      0.74      0.63       397\n",
      "\n",
      "    accuracy                           0.86      2466\n",
      "   macro avg       0.75      0.81      0.77      2466\n",
      "weighted avg       0.88      0.86      0.87      2466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import library \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Separate input features (X) and target variable (y)\n",
    "y = data1.Revenue\n",
    "X = data1.drop('Revenue', axis=1)\n",
    "\n",
    "# standerdize     \n",
    "scaler = MinMaxScaler() # innitialize function\n",
    "x_scaled = scaler.fit_transform(X) # standerdize data (X - no target feature) \n",
    "x_scaled = pd.DataFrame(x_scaled) \n",
    "x_scaled.columns = X.columns # name the columns \n",
    "\n",
    "# lists for f1-score and AUC\n",
    "f1_score_lst = []\n",
    "auc_lst = []\n",
    "\n",
    "# create training and testing vars\n",
    "Xs_train, Xs_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=123, shuffle = True)\n",
    "\n",
    "# begin up-sampling with SMOTE\n",
    "sm = SMOTE(random_state=123, sampling_strategy = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(Xs_train, y_train)\n",
    "\n",
    "# Train model\n",
    "clf_3 = MLPClassifier(random_state = 123, hidden_layer_sizes = (20,40,80))\n",
    "\n",
    "clf_3.fit(x_train_res, y_train_res)\n",
    "\n",
    "# Predict on training set\n",
    "pred_y_3 = clf_3.predict(Xs_test)\n",
    "\n",
    "#10-fold cross validation\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=123, shuffle = True)\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(clf_3, x_train_res, y_train_res, cv=kfold, scoring=scoring)\n",
    "\n",
    "#calculate AUC\n",
    "clf_3_roc_auc = roc_auc_score(y_test, pred_y_3)\n",
    "\n",
    "#calculate average f1-score and AUC\n",
    "f1_score_lst.append(precision_recall_fscore_support(y_test, pred_y_3, average='weighted')[2])\n",
    "auc_lst.append(clf_3_roc_auc)\n",
    "    \n",
    "\n",
    "print('F1 {:.4f}; AUC {:.4f} '.format(np.mean(f1_score_lst),np.mean(auc_lst)))\n",
    "\n",
    "# Is our model still predicting just one class?\n",
    "print('Model is predicting ',np.unique( pred_y_3 ),'class' )\n",
    "\n",
    "print('Accuracy of classifier on test set: {:.3f}'.format(clf_3.score(Xs_test, y_test)))\n",
    "\n",
    "print(\"10-fold cross validation average accuracy of clf_3: %.3f\" % (results.mean()))\n",
    "\n",
    "confusion_matrix_y = confusion_matrix(y_test, pred_y_3)\n",
    "print('Confusion Matrix for Classfier:')\n",
    "print(confusion_matrix_y)\n",
    "\n",
    "print('Classification Report for Classfier:')\n",
    "print(classification_report(y_test, pred_y_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier <a name=\"paragraph5\"></a>\n",
    "Back to [Table of Contents](#t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.8831; AUC 0.8196 \n",
      "Model is predicting  [False  True] class\n",
      "Accuracy of classifier on test set: 0.878\n",
      "10-fold cross validation average accuracy of clf_3: 0.925\n",
      "Confusion Matrix for Classfier:\n",
      "[[1875  194]\n",
      " [ 106  291]]\n",
      "Classification Report for Classfier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.91      0.93      2069\n",
      "        True       0.60      0.73      0.66       397\n",
      "\n",
      "    accuracy                           0.88      2466\n",
      "   macro avg       0.77      0.82      0.79      2466\n",
      "weighted avg       0.89      0.88      0.88      2466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Separate input features (X) and target variable (y)\n",
    "y = data1.Revenue\n",
    "X = data1.drop('Revenue', axis=1)\n",
    "\n",
    "# standerdize     \n",
    "scaler = MinMaxScaler() # innitialize function\n",
    "x_scaled = scaler.fit_transform(X) # standerdize data (X - no target feature) \n",
    "x_scaled = pd.DataFrame(x_scaled) \n",
    "x_scaled.columns = X.columns # name the columns \n",
    "\n",
    "# lists for f1-score and AUC\n",
    "f1_score_lst = []\n",
    "auc_lst = []\n",
    "\n",
    "#loop to calculate f1 and auc scores and present averages after 10 runs\n",
    "for count in range (1,10):\n",
    "\n",
    "    # create training and testing vars\n",
    "    Xs_train, Xs_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=123, shuffle = True)\n",
    "    \n",
    "    # begin up-sampling with SMOTE\n",
    "    sm = SMOTE(random_state=123, sampling_strategy = 'minority')\n",
    "    x_train_res, y_train_res = sm.fit_sample(Xs_train, y_train)\n",
    "\n",
    "    # Train model\n",
    "    clf_3 = XGBClassifier(random_state = 123)\n",
    "\n",
    "    clf_3.fit(x_train_res, y_train_res)\n",
    "\n",
    "    # Predict on training set\n",
    "    pred_y_3 = clf_3.predict(Xs_test)\n",
    "\n",
    "    #10-fold cross validation\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=123, shuffle = True)\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(clf_3, x_train_res, y_train_res, cv=kfold, scoring=scoring)\n",
    "\n",
    "    #calculate AUC\n",
    "    clf_3_roc_auc = roc_auc_score(y_test, pred_y_3)\n",
    "    \n",
    "    #calculate average f1-score and AUC\n",
    "    f1_score_lst.append(precision_recall_fscore_support(y_test, pred_y_3, average='weighted')[2])\n",
    "    auc_lst.append(clf_3_roc_auc)\n",
    "    \n",
    "\n",
    "print('F1 {:.4f}; AUC {:.4f} '.format(np.mean(f1_score_lst),np.mean(auc_lst)))\n",
    "\n",
    "# Is our model still predicting just one class?\n",
    "print('Model is predicting ',np.unique( pred_y_3 ),'class' )\n",
    "\n",
    "print('Accuracy of classifier on test set: {:.3f}'.format(clf_3.score(Xs_test, y_test)))\n",
    "\n",
    "print(\"10-fold cross validation average accuracy of clf_3: %.3f\" % (results.mean()))\n",
    "\n",
    "confusion_matrix_y = confusion_matrix(y_test, pred_y_3)\n",
    "print('Confusion Matrix for Classfier:')\n",
    "print(confusion_matrix_y)\n",
    "\n",
    "print('Classification Report for Classfier:')\n",
    "print(classification_report(y_test, pred_y_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Tree-Based Algorithms: Random Forest <a name=\"paragraph6\"></a>\n",
    "\n",
    "Back to [Table of Contents](#t)\n",
    " \n",
    "- tree models often perform well on imbalanced datasets because their hierarchical structure allows them to learn signals from both classes.\n",
    "- In modern applied machine learning, tree ensembles (Random Forests, Gradient Boosted Trees, etc.) almost always outperform singular decision trees, so we'll jump right into those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.8816; AUC 0.8138 \n",
      "Model is predicting  [False  True] class\n",
      "Accuracy of classifier on test set: 0.877\n",
      "10-fold cross validation average accuracy of clf_4: 0.939\n",
      "Confusion Matrix for Classfier:\n",
      "[[1877  192]\n",
      " [ 111  286]]\n",
      "Classification Report for Classfier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.91      0.93      2069\n",
      "        True       0.60      0.72      0.65       397\n",
      "\n",
      "    accuracy                           0.88      2466\n",
      "   macro avg       0.77      0.81      0.79      2466\n",
      "weighted avg       0.89      0.88      0.88      2466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Separate input features (X) and target variable (y)\n",
    "y = data1.Revenue\n",
    "X = data1.drop('Revenue', axis=1)\n",
    "\n",
    "# standerdize     \n",
    "scaler = MinMaxScaler() # innitialize function\n",
    "x_scaled = scaler.fit_transform(X) # standerdize data (X - no target feature) \n",
    "x_scaled = pd.DataFrame(x_scaled) \n",
    "x_scaled.columns = X.columns # name the columns \n",
    "\n",
    "# lists for f1-score and AUC\n",
    "f1_score_lst = []\n",
    "auc_lst = []\n",
    "\n",
    "#loop to calculate f1 and auc scores and present averages after 10 runs\n",
    "for count in range (1,10):\n",
    "\n",
    "    # create training and testing vars\n",
    "    Xs_train, Xs_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=123, shuffle = True)\n",
    "    \n",
    "    # this is the formula after you split the dataset\n",
    "    sm = SMOTE(random_state=123, sampling_strategy = 'minority')\n",
    "    x_train_res, y_train_res = sm.fit_sample(Xs_train, y_train)\n",
    "\n",
    "    # Train model\n",
    "    clf_5 = RandomForestClassifier(random_state = 123)\n",
    "    clf_5.fit(x_train_res, y_train_res)\n",
    "\n",
    "    # Predict on training set\n",
    "    pred_y_5 = clf_5.predict(Xs_test)\n",
    "\n",
    "    #10-fold cross validation\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=123, shuffle = True)\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(clf_5, x_train_res, y_train_res, cv=kfold, scoring=scoring)\n",
    "\n",
    "    #calculate f1-score and AUC\n",
    "    clf_5_roc_auc = roc_auc_score(y_test, pred_y_5)\n",
    "    \n",
    "    #calculate average f1-score and AUC\n",
    "    f1_score_lst.append(precision_recall_fscore_support(y_test, pred_y_5, average='weighted')[2])\n",
    "    auc_lst.append(clf_5_roc_auc)\n",
    "    \n",
    "    \n",
    "print('F1 {:.4f}; AUC {:.4f} '.format(np.mean(f1_score_lst),np.mean(auc_lst)))\n",
    "\n",
    "# Is our model still predicting just one class?\n",
    "print('Model is predicting ',np.unique( pred_y_5 ),'class' )\n",
    "\n",
    "print('Accuracy of classifier on test set: {:.3f}'.format(clf_5.score(Xs_test, y_test)))\n",
    "\n",
    "print(\"10-fold cross validation average accuracy of clf_4: %.3f\" % (results.mean()))\n",
    "\n",
    "confusion_matrix_y = confusion_matrix(y_test, pred_y_5)\n",
    "print('Confusion Matrix for Classfier:')\n",
    "print(confusion_matrix_y)\n",
    "\n",
    "print('Classification Report for Classfier:')\n",
    "print(classification_report(y_test, pred_y_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree <a name=\"paragraph10\"></a>\n",
    "\n",
    "Back to [Table of Contents](#t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-82625aeed91e>, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-82625aeed91e>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    Xs_train, Xs_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2 random_state=123, shuffle = True)\u001b[0m\n\u001b[0m                                                                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Imported the needed packages\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "# if you want to draw the tree you need these packages \n",
    "#from sklearn.tree import export_graphviz\n",
    "#from sklearn.externals.six import StringIO  \n",
    "#from IPython.display import Image  \n",
    "#import pydotplus\n",
    "\n",
    "# Separate input features (X) and target variable (y)\n",
    "y = data1.Revenue\n",
    "X = data1.drop('Revenue', axis=1)\n",
    "\n",
    "# standerdize     \n",
    "scaler = MinMaxScaler() # innitialize function\n",
    "x_scaled = scaler.fit_transform(X) # standerdize data (X - no target feature) \n",
    "x_scaled = pd.DataFrame(x_scaled) \n",
    "x_scaled.columns = X.columns # name the columns \n",
    "\n",
    "# lists for f1-score and AUC\n",
    "f1_score_lst = []\n",
    "auc_lst = []\n",
    "\n",
    "#loop to calculate f1 and auc scores and present averages after 10 runs\n",
    "for count in range (1,10):\n",
    "\n",
    "    # create training and testing vars\n",
    "    Xs_train, Xs_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2 random_state=123, shuffle = True)\n",
    "    \n",
    "    sm = SMOTE(random_state=123, sampling_strategy = 'minority')\n",
    "    x_train_res, y_train_res = sm.fit_sample(Xs_train, y_train)\n",
    "\n",
    "    # Train model\n",
    "    clf_6 = DecisionTreeClassifier(random_state = 123)\n",
    "    clf_6.fit(x_train_res, y_train_res)\n",
    "\n",
    "    # Predict on training set\n",
    "    pred_y_6 = clf_6.predict(Xs_test)\n",
    "\n",
    "    #10-fold cross validation\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=123, shuffle = True)\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(clf_6, x_train_res, y_train_res, cv=kfold, scoring=scoring)\n",
    "\n",
    "    #calculate f1-score and AUC\n",
    "    clf_6_roc_auc = roc_auc_score(y_test, pred_y_6)\n",
    "    \n",
    "    #calculate average f1-score and AUC\n",
    "    f1_score_lst.append(precision_recall_fscore_support(y_test, pred_y_6, average='weighted')[2])\n",
    "    auc_lst.append(clf_6_roc_auc)\n",
    "\n",
    "print('F1 {:.4f}; AUC {:.4f} '.format(np.mean(f1_score_lst),np.mean(auc_lst)))\n",
    "\n",
    "# Is our model still predicting just one class?\n",
    "print('Model is predicting ',np.unique( pred_y_6 ),'class' )\n",
    "\n",
    "print('Accuracy of classifier on test set: {:.3f}'.format(clf_6.score(Xs_test, y_test)))\n",
    "\n",
    "print(\"10-fold cross validation average accuracy of clf_4: %.3f\" % (results.mean()))\n",
    "\n",
    "confusion_matrix_y = confusion_matrix(y_test, pred_y_6)\n",
    "print('Confusion Matrix for Classfier:')\n",
    "print(confusion_matrix_y)\n",
    "\n",
    "print('Classification Report for Classfier:')\n",
    "print(classification_report(y_test, pred_y_6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- results are not as good as random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
