{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization\n",
    "We run **gridsearchCV** and **randomsearchCV** to get the best parameters possible. We still run the model on the same features. \n",
    "\n",
    "### Results: <a name=\"t\"></a>\n",
    "\n",
    "1. GridSearchCV: [XGBoost](#xgb) \n",
    "- AUC score: 0.884893 \n",
    "- Parameters: <span style=\"color:red\">{'learning_rate': 0.3, 'loss': 'deviance', 'max_depth': 11, 'max_leaf_nodes': 1, 'n_estimators': 110, 'subsample': 1.0}</span>\n",
    "\n",
    "2. GridSearchCV: [KNN](#knn)\n",
    "- AUC score: 0.878967\n",
    "- Parameters: <span style=\"color:red\">{'algorithm': 'auto', 'leaf_size': 20, 'metric': 'minkowski', 'n_neighbors': 4, 'p': 3, 'weights': 'distance'}</span>\n",
    "\n",
    "3. GridSearchCV: [Random Forest](#rf)\n",
    "- AUC score: 0.872383 \n",
    "- Parameters: <span style=\"color:red\">{'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 20, 'max_features': 0.4, 'max_leaf_nodes': 5, 'min_samples_leaf': 20, 'min_samples_split': 14, 'n_estimators': 100}</span>\n",
    "\n",
    "4. RandomSearchCV: [SVC](#svc) \n",
    "- AUC score: 0.850234 \n",
    "- Parameters: <span style=\"color:red\">{'kernel': 'rbf', 'gamma': 1.0672387970376063, 'class_weight': 'balanced', 'C': 0.8914369396699439}</span>\n",
    "\n",
    "5. GridSearchCV: [Logistic Regression](#lr) \n",
    "- AUC score: 0.847899 \n",
    "    - Parameters: <span style=\"color:red\">{'C': 5, 'class_weight': <class 'dict'>, 'dual': False, 'max_iter': 90, 'solver': 'lbfgs', 'verbose': 0, 'warm_start': True}</span>\n",
    "\n",
    "6. GridSearchCV: [MLP](#mlp) \n",
    "- AUC score: 0.847720\n",
    "- Parameters: <span style=\"color:red\">{'activation': 'identity', 'alpha': 0.0003, 'hidden_layer_sizes': (20, 40), 'learning_rate': 'constant', 'solver': 'lbfgs', 'verbose': True}</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "\n",
    "# Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics, model_selection\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('all_model_data.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12330, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch CV\n",
    "\n",
    "### 1. Logistic Regression <a name=\"lr\"></a>\n",
    "\n",
    "Back to [results](#t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select x and y\n",
    "X = data[['ProdRelPageRatio_Scaled_Bin','totalFracAdmin_Scaled','Administrative_Duration_Scaled'\n",
    "             ,'BounceRates_Norm_Scaled', 'ExitRates_Scaled','SpecialDay_1.0']]\n",
    "y = data.Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.847899 using {'C': 5, 'class_weight': <class 'dict'>, 'dual': False, 'max_iter': 90, 'solver': 'lbfgs', 'verbose': 0, 'warm_start': True}\n"
     ]
    }
   ],
   "source": [
    "# we will use AUC to check validity of hyperparameters \n",
    "scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "# Split the `digits` data into two equal sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, shuffle = True)\n",
    "\n",
    "# balance the data\n",
    "sm = SMOTE(random_state=123, sampling_strategy = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "# create options for gridsearch (it will iterate through all these options)\n",
    "dual=[True,False]\n",
    "C = [3,5,7]\n",
    "max_iter=[90,100,110]\n",
    "solver = ['lbfgs','newton-cg']\n",
    "verbose = [0,1,2]\n",
    "warm_start = [True, False]\n",
    "class_weight = [dict,'balanced',None]\n",
    "\n",
    "param_grid = dict(dual=dual,C=C,max_iter=max_iter,solver=solver,warm_start=warm_start,class_weight=class_weight,\n",
    "                 verbose=verbose)\n",
    "\n",
    "# Create a classifier with the parameter candidates\n",
    "grid = GridSearchCV(estimator=LogisticRegression(random_state=123), param_grid=param_grid, n_jobs=-1,scoring=scorer,\n",
    "                    cv = 3)\n",
    "\n",
    "# fit grid to the model\n",
    "grid_result = grid.fit(x_train_res, y_train_res)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Search: SVC <a name=\"svc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Month_bin_2','Month_bin_4','Month_bin_1','totalFracProd_Bin',\n",
    "              'ProdRelPageRatio_Scaled_Bin','BounceExitAvg_Norm_Scaled','totalFracInfo_Scaled']]\n",
    "y = data.Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.850234 using {'kernel': 'rbf', 'gamma': 1.0672387970376063, 'class_weight': 'balanced', 'C': 0.8914369396699439}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "\n",
    "# Split the `digits` data into two equal sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, shuffle = True)\n",
    "\n",
    "# balance the data\n",
    "sm = SMOTE(random_state=123, sampling_strategy = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "# Initialize the random number generator\n",
    "np.random.seed(123)\n",
    "# Create range of values to choose randomly from \n",
    "C1 = np.random.normal(1,0.1,1).astype(float)\n",
    "kernel = np.random.choice(['rbf','sigmoid'],1)\n",
    "gamma = np.random.uniform(0.1,1.5,1)\n",
    "class_weight = np.random.choice([dict,'balanced'],1)\n",
    "\n",
    "# join the parameter grid into a dictionary \n",
    "param_grid1 = dict(C=C1,kernel=kernel,gamma=gamma,class_weight=class_weight)\n",
    "\n",
    "# innitialize the model \n",
    "rfr = SVC(random_state = 123)\n",
    "# use auc to score\n",
    "scorer = make_scorer(roc_auc_score)\n",
    "# innitialize random search, put param grid in, use cv=3, use all processors\n",
    "random = RandomizedSearchCV(estimator=rfr, param_distributions=param_grid1, cv = 3, n_jobs=-1,scoring=scorer)\n",
    "\n",
    "#fit the model\n",
    "random_result = random.fit(x_train_res, y_train_res)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Grid Search: MLP <a name=\"mlp\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['PageValues_Scaled_Bin', 'ExitRates_Scaled']]\n",
    "y = data.Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.847720 using {'activation': 'identity', 'alpha': 0.0003, 'hidden_layer_sizes': (20, 40), 'learning_rate': 'constant', 'solver': 'lbfgs', 'verbose': True}\n"
     ]
    }
   ],
   "source": [
    "# we will use AUC to check validity of hyperparameters \n",
    "scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "# Split the `digits` data into two equal sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, shuffle = True)\n",
    "\n",
    "# balance the data\n",
    "sm = SMOTE(random_state=123, sampling_strategy = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "# Set the parameter candidates\n",
    "hidden_layer_sizes=[(20,40),(20,40,80),(40,80)]\n",
    "activation = ['identity','logistic','relu']\n",
    "solver = ['lbfgs','solver']\n",
    "alpha = [0.0003,0.0005,0.0007]\n",
    "max_iter = [200,300,400]\n",
    "learning_rate = ['constant', 'invscaling', 'adaptive']\n",
    "#max_fun = [15000,17000]\n",
    "verbose = [True,False]\n",
    "\n",
    "# create param grid (join them in the dictionary)\n",
    "param_grid = dict(hidden_layer_sizes=hidden_layer_sizes,activation=activation,solver=solver,alpha=alpha,\n",
    "                 learning_rate=learning_rate,verbose=verbose,max_iter=max_iter)\n",
    "\n",
    "# Create a classifier with the parameter candidates\n",
    "grid1 = GridSearchCV(estimator=MLPClassifier(random_state=123), param_grid=param_grid, n_jobs=-1, scoring = scorer, cv = 3)\n",
    "\n",
    "# Train the classifier on training data\n",
    "grid_results1 = grid1.fit(x_train_res, y_train_res)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_results1.best_score_, grid_results1.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Grid Search: XGBoost <a name=\"xgb\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['PageValues_Norm_Scaled','AdminBounceRatio_Norm_Scaled','ProdRelExitRatio_Norm_Scaled',\n",
    "              'Month_bin_4','Month_bin_2','VisitorType_bin_2','Informational_Duration_Scaled','totalFracProd_Bin']]\n",
    "y = data.Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.884893 using {'learning_rate': 0.3, 'loss': 'deviance', 'max_depth': 11, 'max_leaf_nodes': 1, 'n_estimators': 110, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# we will use AUC to check validity of hyperparameters \n",
    "scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "# Split the `digits` data into two equal sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, shuffle = True)\n",
    "\n",
    "# balance the data\n",
    "sm = SMOTE(random_state=123, sampling_strategy = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "# Set the parameter candidates\n",
    "loss = ['deviance', 'exponential']\n",
    "learning_rate = [0.3,0.4,0.5]\n",
    "n_estimators = [110,120,130]\n",
    "subsample = [0.8,1.0,1.2]\n",
    "max_depth = [9,11,13]\n",
    "max_leaf_nodes = [1,2,None]\n",
    "\n",
    "# create param grid (join them in the dictionary)\n",
    "param_grid = dict(loss=loss,learning_rate=learning_rate,n_estimators=n_estimators,subsample=subsample,\n",
    "                 max_depth=max_depth,max_leaf_nodes=max_leaf_nodes)\n",
    "\n",
    "# Create a classifier with the parameter candidates\n",
    "grid2 = GridSearchCV(estimator=XGBClassifier(random_state=123), param_grid=param_grid, n_jobs=-1, scoring = scorer, cv = 3)\n",
    "\n",
    "# Train the classifier on training data\n",
    "grid_results2 = grid2.fit(x_train_res, y_train_res)\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (grid_results2.best_score_, grid_results2.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Grid Search: Random Forest <a name=\"rf\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['ProductRelated_Duration_Scaled','BounceRates_Scaled','PageValues_Scaled','totalFracAdmin_Scaled',\n",
    "         'Month_bin_2','ExitRates_Scaled']]\n",
    "y = data.Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.872383 using {'bootstrap': False, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 20, 'max_features': 0.4, 'max_leaf_nodes': 5, 'min_samples_leaf': 20, 'min_samples_split': 14, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# we will use AUC to check validity of hyperparameters \n",
    "scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "# Split the `digits` data into two equal sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, shuffle = True)\n",
    "\n",
    "# balance the data\n",
    "sm = SMOTE(random_state=123, sampling_strategy = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "# Set the parameter candidates\n",
    "n_estimators= [100]\n",
    "max_depth= [10, 20]\n",
    "max_leaf_nodes= [2,5]\n",
    "class_weight= [None,'balanced']\n",
    "bootstrap = [True, False]\n",
    "criterion=['entropy','giny']\n",
    "max_features=['auto',0.4]\n",
    "min_samples_leaf=[15,20]\n",
    "min_samples_split=[12,14]\n",
    "\n",
    "# create param grid (join them in the dictionary)\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth, max_leaf_nodes=max_leaf_nodes, class_weight=class_weight,\n",
    "                 bootstrap=bootstrap,criterion=criterion,max_features=max_features,min_samples_leaf=min_samples_leaf,\n",
    "                 min_samples_split=min_samples_split)\n",
    "\n",
    "# Create a classifier with the parameter candidates\n",
    "clf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, n_jobs=-1, scoring = scorer, cv=3)\n",
    "\n",
    "# Train the classifier on training data\n",
    "grid_result= clf.fit(x_train_res, y_train_res)\n",
    "\n",
    "# Print out the results \n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Grid Search: KNN <a name=\"knn\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['PageValues_Norm_Scaled','ExitRates_Scaled','totalFracProd_Scaled']]\n",
    "y = data.Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.878967 using {'algorithm': 'auto', 'leaf_size': 20, 'metric': 'minkowski', 'n_neighbors': 4, 'p': 3, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# we will use AUC to check validity of hyperparameters \n",
    "scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "# Split the `digits` data into two equal sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123, shuffle = True)\n",
    "\n",
    "# balance the data\n",
    "sm = SMOTE(random_state=123, sampling_strategy = 'minority')\n",
    "x_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "# Set the parameter candidates\n",
    "n_neighbors= [4,5,6]\n",
    "weights= ['uniform','distance']\n",
    "algorithm= ['auto', 'ball_tree','kd_tree']\n",
    "leaf_size=[20,30,40]\n",
    "p=[3,4]\n",
    "metric= ['minkowski']\n",
    "\n",
    "# create param grid (join them in the dictionary)\n",
    "param_grid = dict(n_neighbors=n_neighbors, weights=weights, algorithm=algorithm, leaf_size=leaf_size, p=p, metric=metric)\n",
    "\n",
    "# Create a classifier with the parameter candidates\n",
    "clf = GridSearchCV(estimator=KNeighborsClassifier(), param_grid=param_grid, n_jobs=-1, scoring = scorer, cv=10)\n",
    "\n",
    "# Train the classifier on training data\n",
    "grid_result= clf.fit(x_train_res, y_train_res)\n",
    "\n",
    "# Print out the results \n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
